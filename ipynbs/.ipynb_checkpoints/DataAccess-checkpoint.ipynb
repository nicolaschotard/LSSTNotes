{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the DB\n",
    "The code is avaible on the SNfactory CVS (https://cvs.in2p3.fr/snovae-SNFactory/), and is located under\n",
    "\n",
    "    SNFactory/Tasks/Processing/database/django/processing_095.\n",
    "\n",
    "If you have it installed on your personnal computer and are not in a IN2P3 network, you can still have a local access to the DB by tunneling `localhost:5432` to `ccpgsql.in2p3.fr:5432`, e.g.:\n",
    "\n",
    "    ssh -C -N snprod@ccage.in2p3.fr -L 5432/ccpgsql.in2p3.fr/5432\n",
    "    \n",
    "If you do not have a CVS access, have a look at the following [wepage](http://supernova.in2p3.fr/doc/ccin2p3/help_user/cvs_1.html.en)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First queries\n",
    "\n",
    "Here are a few simple examples of how to get data or information from the DB. Let's first say that you want all the type Ia supernova, you will query the **Target** table and **filter** the **objects** by asking for specific *Kind* and *Type*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "824 type Ia supernovae found in the DB\n"
     ]
    }
   ],
   "source": [
    "from processing.process.models import Target, Run, Exposure, Pose, Process, File, Job\n",
    "sneia = Target.objects.filter(Kind='SuperNova', Type='Ia')\n",
    "print \"%i type Ia supernovae found in the DB\" % sneia.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you now want their respective name and number of run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASASSN_13bb: 7 runs\n",
      "SN2004dt: 252 runs\n",
      "SN2004ea: 2 runs\n",
      "SN2004ef: 124 runs\n",
      "SN2004gc: 101 runs\n"
     ]
    }
   ],
   "source": [
    "name_run = [(tg.Name, tg.Runs_FK.all().count()) for tg in sneia[:5]]\n",
    "for n, r in name_run:\n",
    "    print \"%s: %i runs\" %(n, r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, the *tg* object contains all the attributes of the **Target** table (see the figure above). You can thus access to all these elements simply by querying its attribtues:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kind SuperNova\n",
      "PI SNfactory\n",
      "Name PTF09dlc\n",
      "IdTarget T09239059\n",
      "DateM 2009-10-11 18:18:16.454216\n",
      "DateC 2009-09-20 06:48:01.105199\n",
      "Ra 326.625416667\n",
      "IAUC None\n",
      "Dec 6.41921944444\n",
      "Type Ia\n",
      "id 3021\n"
     ]
    }
   ],
   "source": [
    "tg = Target.objects.get(Name='PTF09dlc') # we take one target as an example\n",
    "for at in tg.__dict__:\n",
    "    print at, tg.__getattribute__(at)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for the other tables, the Target model has also many methods from which you can get other information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Redshift: RedshiftHelio (PTF09dlc) - 0.06737 +- 5e-05\n",
      "MWebv: MilkyWayExtinction (PTF09dlc) - 0.0541 +- None\n",
      "Followed?: True\n",
      "# of observation nights: 16\n"
     ]
    }
   ],
   "source": [
    "print \"Redshift:\", tg.Redshift\n",
    "print \"MWebv:\", tg.MWebv\n",
    "print \"Followed?:\", tg.followed(nnights=3)\n",
    "print \"# of observation nights:\", tg.nnights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Process table\n",
    "\n",
    "The Process table is the heart of the DB. You can, from a given process, access **all** the information about its corresponding file, job, run, etc. Indeed, a process is always linked to only one file, only one job, only one run, etc, which is not true for a target, which have most of the time many runs, each of them having many exposures, etc. If we come back to the previous target *tg* that we were using as an example in the previous section, we can go from the **Target** table to the **Process** table by going down through all the other tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All runs for this target 42\n",
      "All exposures for this run 4\n",
      "All poses for this exposure 3\n",
      "All processes for this pose 211\n",
      "A given process from the list of processess 923906000346401100203001\n"
     ]
    }
   ],
   "source": [
    "# There is an 's' since a target can have several Runs\n",
    "# Also true for the other table when you go down from Target to Process\n",
    "runs = tg.Runs_FK.all()\n",
    "print \"All runs for this target\", runs.count()\n",
    "r = runs[5]\n",
    "exps = r.Exposures_FK.all()\n",
    "print \"All exposures for this run\", exps.count()\n",
    "e = exps[2]\n",
    "poses = e.Poses_FK.all()\n",
    "print \"All poses for this exposure\", poses.count()\n",
    "p = poses[1]\n",
    "procs = p.Processes_FK.all()\n",
    "print \"All processes for this pose\", procs.count()\n",
    "proc = procs[10]\n",
    "print \"A given process from the list of processess\", proc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now take this process, we can go back up to its corresponding target through all the other tables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The process 923906000346401100203001\n",
      "Its pose 92390600034\n",
      "Its exposure 9239060003\n",
      "Its run 9239060\n",
      "Its target T09239059\n",
      "The target name PTF09dlc\n"
     ]
    }
   ],
   "source": [
    "# No 's' here since a process only has one associated \n",
    "# Pose, Exposure, Run and Target\n",
    "print \"The process\", proc\n",
    "print \"Its pose\", proc.Pose_FK \n",
    "print \"Its exposure\", proc.Pose_FK.Exp_FK\n",
    "print \"Its run\", proc.Pose_FK.Exp_FK.Run_FK\n",
    "print \"Its target\", proc.Pose_FK.Exp_FK.Run_FK.TargetId_FK\n",
    "print \"The target name\", proc.Pose_FK.Exp_FK.Run_FK.TargetId_FK.Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or go down to its correspond file or to the job that produced it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Its file 09_239_060_003_4_640_110_02-03_001.fits and the file FullPath:\n",
      "/sps/snovae/SRBregister/Prod/02-03/09/239/09_239_060_003_4_640_110_02-03_001.fits\n"
     ]
    }
   ],
   "source": [
    "print \"Its file\", proc.File_FK, \"and the file FullPath:\"\n",
    "print proc.File_FK.FullPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the job id: 253926, and its name: SNF-0203-NEWYORKf-09dlc\n"
     ]
    }
   ],
   "source": [
    "print \"the job id: %s, and its name: %s\" % (proc.Job_FK.id, proc.Job_FK.Name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not that easy to get all the process of a given target by making a query on the Target table (way too complicated to show that here), while it is simple to do it using the Process table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13127\n"
     ]
    }
   ],
   "source": [
    "procs = Process.objects.filter(Pose_FK__Exp_FK__Run_FK__TargetId_FK__Name='PTF09dlc')\n",
    "print procs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auxiliary files\n",
    "\n",
    "When a code is run, it usually produces one or more main output files, which will be associated to the same amount of processes in the DB, all separatly linked to the input file(s) used to produce them, i.e. their parents. If the main output files have associated ***auxiliary*** files (e.g., PNG plots, fits tables, yaml or json files, etc.), they will be added to the AuxFile table and will be directly linked to the main process. They won't exist in the DB in the Processs table, but in the File table only. Here is an example using the PSF-subtracted cubes produced by plan_extract_star when run on cubefit output cubes (Fclass=270, XFclass=800):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The associated file 11_327_070_003_2_270_800_02-03_002.fits\n",
      "1 auxiliary file [11_327_070_003_2_270_801_02-03_002.fits]\n"
     ]
    }
   ],
   "source": [
    "# Let's only take the first one of the list\n",
    "cube = Process.objects.filter(Fclass=270, XFclass=800)[0]\n",
    "print \"The associated file\", cube.File_FK\n",
    "print \"%i auxiliary file\" % (cube.AuxFiles_FK.all().count()), cube.AuxFiles_FK.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try to get this auxiliary file from the DB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From the Process table []\n",
      "From the File table [12_292_064_003_4_270_801_00-13_000.fits]\n"
     ]
    }
   ],
   "source": [
    "fname = '12_292_064_003_4_270_801_00-13_000.fits'\n",
    "print \"From the Process table\", Process.objects.filter(File_FK__Name=fname)\n",
    "print \"From the File table\", File.objects.filter(Name=fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, an auxiliary file is actualy like any other regular file and can thus be queried from the File table. In the hother hand, auxiliary files are not dirrectly associated to a process, i.e:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No direct process association:  []\n",
      "But an AuxFile process association:  [1229206400342708000013000]\n"
     ]
    }
   ],
   "source": [
    "f = File.objects.get(Name='12_292_064_003_4_270_801_00-13_000.fits')\n",
    "print \"No direct process association: \", f.Processes_FK.all()\n",
    "print \"But an AuxFile process association: \", f.AuxFile_of_Processes_FK.all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parent and Child\n",
    "\n",
    "A given process is always produced by a plan, which is using input files to produce them. We thus say that a given process has *parent*, and since they can also be used to produce other files/process, they most of the time have *child*. A process will always have the Parent_FK and Child_FK attributes. These attributes point to the Process table, and thus have all its propoerties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 parents: [923900000019950000200000, 923906000340381000203000, 923906000316257000203001, 923904400346307000203001]\n",
      "1 children: [923906000346661100203001]\n",
      "Filter the children Fclass=280 []\n"
     ]
    }
   ],
   "source": [
    "print \"%i parents:\" % proc.Parent_FK.all().count(), proc.Parent_FK.all()\n",
    "print \"%i children:\" % proc.Child_FK.all().count(), proc.Child_FK.all()\n",
    "print \"Filter the children Fclass=280\", proc.Child_FK.filter(Fclass=280)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also make queries on processes and ask for specific parents or child properties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "363 processes\n",
      "With Fclass set([(22, 0)])\n"
     ]
    }
   ],
   "source": [
    "# XFclass=901 are the synthetic arcs\n",
    "procs = Process.objects.filter(Parent_FK__XFclass=901) \n",
    "print procs.count(), 'processes'\n",
    "# Cubes produced with synthetic arcs\n",
    "print 'With Fclass', set([(p.Fclass, p.XFclass) for p in procs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other possible queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First query 426299\n",
      "Second query 18873\n",
      "Third query 4470\n",
      "Fourth query 1481\n",
      "Fifth query 1481\n",
      "Last query 2336\n"
     ]
    }
   ],
   "source": [
    "# use \"__in\" to select in a list\n",
    "procs = Process.objects.filter(Fclass__in=[17, 18])\n",
    "print \"First query\", procs.count()\n",
    "# you can apply other filters to a query output\n",
    "procs = procs.filter(Pose_FK__Exp_FK__Run_FK__Year=5)\n",
    "print \"Second query\", procs.count()\n",
    "# you can also exclude objects in a query\n",
    "# __gt stands for 'greater than'\n",
    "procs = procs.exclude(Pose_FK__Exp_FK__Run_FK__Day__gt=125)\n",
    "print \"Third query\", procs.count()\n",
    "# __cointains, __startswith, __endswith are other \n",
    "# django operators that you can use in a query\n",
    "procs = procs.filter(Job_FK__Name__startswith='SNF-020')\n",
    "print \"Fourth query\", procs.count()\n",
    "# regular expression can also be used\n",
    "procs = procs.filter(Job_FK__Name__regex='SNF-020')\n",
    "print \"Fifth query\", procs.count()\n",
    "# and you can also look for null values\n",
    "runs = Run.objects.filter(Type='SPECTRED', TargetId_FK__isnull=True)\n",
    "print \"Last query\", runs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One query is better than many\n",
    "\n",
    "One big query to the DB is always faster than many smaller ones. So if possible, find a way to make as less query as possible when looking for info in the DB. Here is a example of the speed difference and the time that you can save making the *good* query:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processes found: 140\n",
      "First test: many small queries\n",
      "1 loops, best of 3: 25.2 s per loop\n",
      "Second test: one big querie\n",
      "1 loops, best of 3: 1.1 s per loop\n"
     ]
    }
   ],
   "source": [
    "# get all the SALT2 yaml file (F/XFclass=700,720) of a given job (BEDELL) \n",
    "# for targets having a name starting with 'SNF' \n",
    "procs = Process.objects.filter(Fclass=700, XFclass=720, \n",
    "                               Pose_FK__Exp_FK__Run_FK__TargetId_FK__Name__startswith='SNF', \n",
    "                               Job_FK__Name__contains='BEDELL')\n",
    "print 'Processes found:', procs.count()\n",
    "# now let's take their id\n",
    "idprocs = [p.IdProcess for p in procs]\n",
    "# and do it again in two different ways that will give the same results\n",
    "# the first way is using a comprehension list and make many queries to the DB\n",
    "print \"First test: many small queries\"\n",
    "%timeit([Process.objects.get(IdProcess=p) for p in idprocs])\n",
    "# the second makes only one query\n",
    "print \"Second test: one big querie\"\n",
    "%timeit([p for p in Process.objects.filter(IdProcess__in=idprocs)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said, making one big querie can be much faster than making a lot of small ones. \n",
    "\n",
    "### Compact query\n",
    "\n",
    "Here is a Django tool to make more compact and readable queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140\n"
     ]
    }
   ],
   "source": [
    "from django.db.models import Q\n",
    "q = Q(Fclass=700)\n",
    "q &= Q(Job_FK__Name__startswith='SNF-0200-BEDELL')\n",
    "q &= Q(Pose_FK__Exp_FK__Run_FK__TargetId_FK__Name__startswith='SNF')\n",
    "procs = Process.objects.filter(q)\n",
    "print procs.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is also a python library called **fetchKeys** that simplify queries to the DB. It is using queries like the ones shown in this page. It is well documented (*fetchKeys --doc*), so you can have a look at the code and usage examples. It is on CVS under ~/SNFactory/Tasks/Processing/scripts and is installed at the CC. It can be used on command line or be imported as a python library.\n",
    "\n",
    "For a more complete description of the available Django-operators, please have a look [here](https://docs.djangoproject.com/en/dev/ref/models/querysets/#field-lookups), and more generally at the Djando [online Documentation](https://docs.djangoproject.com/en/1.7/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the IDR\n",
    "\n",
    "### Shortcuts to the IDRs\n",
    "\n",
    "Here are web links to the lattest produced IDRs for the different samples:\n",
    "\n",
    "* SNe Ia: SNF-0203-ALLEG2a_SNeIa ([tarball](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-ALLEG2a_SNeIa.tar.bz2), [manifest](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-ALLEG2a_SNeIa/MANIFEST.md5), [config](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-ALLEG2a_SNeIa/CONFIG.yaml), [meta](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-ALLEG2a_SNeIa/META.yaml))\n",
    "* Other SN types: SNF-0203-ALLEG2a_otherSNe ([tarball](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-ALLEG2a_otherSNe.tar.bz2), [manifest](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-ALLEG2a_otherSNe/MANIFEST.md5), [config](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-ALLEG2a_otherSNe/CONFIG.yaml), [meta](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-ALLEG2a_otherSNe/META.yaml))\n",
    "* Standard stars: SNF-0203-NEWYORKa_StdStar ([tarball](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-NEWYORKa_StdStar.tar.bz2), [manifest](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-NEWYORKa_StdStar/MANIFEST.md5), [config](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-NEWYORKa_StdStar/CONFIG.yaml), [meta](http://snovae.in2p3.fr/snprod/Data/IDR/SNF-0203-NEWYORKa_StdStar/META.yaml))\n",
    "\n",
    "The manifest, config and meta pickle files are included in their respective IDR (tarball).\n",
    "\n",
    "### General description\n",
    "\n",
    "The SNfactory Internal Data Release (IDR) has been build to give an easy access to the final SNfactory spectral data in order to simplify the data analysis. It is divided into three independent files and directories respectively containing the type Ia supernovae sample, the type II-Ic-Ib/c supernovae sample, and the standard stars sample. IDRs all contain data corresponding to the same version of the SNfactory calibration pipeline (flux calibrated for standard stars, flux calibrated and host-subtracted for the supernova samples). Their associated job can be found on the SNfactory [zoo](http://snf.in2p3.fr/zoo), as well as in the production analysis [web page](http://snf.in2p3.fr/prod). There is also a webpage containing links to older IDRs available [here](http://snovae.in2p3.fr/snprod/Data/IDR/index.html).\n",
    "\n",
    "### The IDRs\n",
    "\n",
    "#### The SNe Ia IDR\n",
    "\n",
    "This IDR is divided into two sub sets:\n",
    "\n",
    "* the **bad** sample, which corresponds to supernovae for which the SALT2 ([Guy et al 2010](http://cdsads.u-strasbg.fr/abs/2010A%26A...523A...7G)) light curve fit do not pass the quality criteria described below;\n",
    "* and the **good** sample, which has only supernovae passing these same quality cuts, and which is itself divided into three sub-sets:\n",
    "    *   the **training** sample;\n",
    "    *   the **validation** sample;\n",
    "    *   and the **auxiliary** sample.\n",
    "\n",
    "The **training** and **validation** samples are divided in a consistent way in order to have the same statistical properties in both of them, i.e, same x1, c, phase, z distributions. The **auxiliary** sample contains 'peculiar' objects, which could be peculiar SNe Ia (super-C, etc.) or potential non-SNe Ia objects. It also contains SNe Ia with strong galaxy contamination. They all have been put in this sample manually. See the CONFIG.yaml file of a given IDR for a better description of the sample.\n",
    "\n",
    "The SALT2 fit quality cuts mentioned above are currently the following:\n",
    "\n",
    "*   At least 5 nights of observation;\n",
    "*   Less than 20% of point rejection (after outliers cut > 0.2 mag);\n",
    "*   nMAD of the global residuals must be < 0.12 mag (in the BVR bands);\n",
    "*   Minimal phase coverage including:\n",
    "    *   4 epochs in [-10 < p < +35] days,\n",
    "    *   1 epoch in [-10 < p < +7] days,\n",
    "    *   1 epoch in [+7 < p < +20] days,\n",
    "    *   1 color in [-8 < p < +10] days.\n",
    "\n",
    "If one of these quality cuts is not satisfied, then the considered object is put into the _bad_ sample. Otherwise, it goes into the **good** sample. This separation into **good** and **bad** is automatically done by `study_flux_quality.py` (in CVS, under `SNFactory/Tasks/HEAD/Processing/metrics/`). Keep in mind that a supernovae from the bad sample doesn't necessary have bad quality data. It only means that the fit to the SALT2 model would probably not be used for cosmology analysis. But it could be perfectly fine for any other kind of analysis (color, spectral, etc.).\n",
    "\n",
    "**WARNING:** All new analysis must be started with the **training** sample only.\n",
    "\n",
    "#### The other SN types IDR\n",
    "\n",
    "This \"other type\" supernovae IDR contains all targets/spectra of a given production having a Target.Type different than \"Ia\" (actually a startsiwht). You will thus find in this IDR all our **type II** and **type Ib/c** supernovae. Appart from the SALT2 information and their derived quantities (phase), the content of this IDR is the same as the type Ia one. The sub-sampling of this IDR uses the Target.Type of the DB objects (**II**, **IIP**, **Ib**, **Ib/c**, **Ic**).\n",
    "\n",
    "#### The standard stars IDR\n",
    "\n",
    "The standard stars IDR contains all the standard stars found in the DB for a given production. The sub-sampling is made using the Target.Kind of the DB objects (**StdStar**, **StdStar-Faint**, **StdStar-SNLS**). It contains the basic same information as the \"other type\" supernovae IDR.\n",
    "\n",
    "#### More info\n",
    "\n",
    "##### In the IDR\n",
    "\n",
    "See the \"CONFIG.yaml\" and \"README.txt\" files of a given IDR to have more information (see above for an example). See also the README.txt file of each target which contains information on a given target and for a given SNf production. An example for SNF20070420-001 in **ACEv3** can be found at this [location](http://snovae.in2p3.fr/snprod/Data/IDR/ACEv3/training/SNF20070420-001/README.txt). The IDR data are also available on the CC in2p3 under: `/afs/in2p3.fr/group/snovae/snprod1/IDR/`. \n",
    "\n",
    "You will also find in each IDR a extra pkl file called **DBINFO.pkl** containing all the DB tables info corresponding to each target/spectrum of the IDR, along with photometricity and MFR data.\n",
    "\n",
    "##### Notes\n",
    "\n",
    "*   A [presentation](http://snovae.in2p3.fr/snprod/Data/IDR/Notes/IDRTutorial.pdf) of the IDR by Stephen at the 2010 Bonn meeting.\n",
    "*   A [note](http://snovae.in2p3.fr/snprod/Data/IDR/Notes/idr_restframe.pdf) written by Stephen and Rollin about the definition of a rest-frame spectrum in the IDR, also available [on CVS](https://cvs.in2p3.fr/snovae-SNFactory/Analysis/idr_restframe/).\n",
    "\n",
    "##### Tools\n",
    "\n",
    "*   Some tools to build you own IDR, or to study a given IDR, available [on CVS](https://cvs.in2p3.fr/snovae-SNFactory/Tasks/IDR/).\n",
    "*   The **DRE**: **D**ata **R**elease **E**xplorer. Used to parse the IDR data. Available [on CVS](https://cvs.in2p3.fr/snovae-SNFactory/Offline/DRE/). See the [README](https://cvs.in2p3.fr/snovae-SNFactory/~checkout~/Offline/DRE/README.org?rev=1.5&content-type=text/plain) and a [presentation](http://snovae.in2p3.fr/snprod/Data/IDR/Notes/DRE.pdf) made at the 2011 Lyon meeting for more information.\n",
    "*   **SnfMetaData**. A python module which can help you to load and manipulate the IDR META.pkl file. Available [on CVS](https://cvs.in2p3.fr/snovae-SNFactory/Tasks/MetaData/). See its internal documentation for examples and available functions, and a presentation available [here](http://snovae.in2p3.fr/snprod/Data/IDR/snfMetaData.html).\n",
    "\n",
    "### How to build an IDR\n",
    "\n",
    "An IDR is build using a configuration file, including a list of object, each one of them being associated to a specific sample (e.g., good, bad, etc. for the Ia SNe). This CONFIG file can be created using a previous IDR configuration file using *update_idr_config.py*. This script can be found under the SNfcatory CVS, at the [following location](https://cvs.in2p3.fr/snovae-SNFactory/Tasks/IDR/update_idr_config.py). From a config file, an IDR can be then built using *build_idr.py*, located [under](https://cvs.in2p3.fr/snovae-SNFactory/Tasks/IDR/build_idr.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From the web\n",
    "\n",
    "The SNfactory online DB interface is located at http://snf.in2p3.fr/. From this web page, many other tools/pages are available. Here is a non-exhaustive list of what is available but non directly apparing on the main page (also available [here](http://snf.in2p3.fr/about/)):\n",
    "\n",
    "### Target/Job oriented\n",
    "\n",
    "* [zoo](http://snf.in2p3.fr/zoo/)\n",
    "* [zoo/SNF-0200-BEDELLa](http://snf.in2p3.fr/zoo/SNF-0200-BEDELLa/) (jobname)\n",
    "* [lc/SNF20070820-000](http://snf.in2p3.fr/lc/SNF20070820-000/) (target)\n",
    "* [lc/SNF-0200-BEDELLa,SNF-0200-NEWHAMPa/SNF20070820-000](http://snf.in2p3.fr/lc/SNF-0200-BEDELLa,SNF-0200-NEWHAMPa/SNF20070820-000/) (jobname1,jobname2,etc/target)\n",
    "* [targetview/SNF20070820-000](http://snf.in2p3.fr/targetview/SNF20070820-000/) (target)\n",
    "\n",
    "### Night oriented\n",
    "\n",
    "* [agenda](http://snf.in2p3.fr/agenda)\n",
    "* [agenda/09344](http://snf.in2p3.fr/agenda/09344/) (YYDDD)\n",
    "\n",
    "### Process/Job history\n",
    "\n",
    "* [history/0423900700111320000202000](http://snf.in2p3.fr/history/0423900700111320000202000/) (IdProcess)\n",
    "* [history/SNF-0203-NEWYORKf](http://snf.in2p3.fr/history/SNF-0203-NEWYORKf/) (Job name)\n",
    "* [history/SNF-0203-ALLEGe-LSQ13abo](http://snf.in2p3.fr/history/SNF-0203-ALLEGe-LSQ13abo/) (Job name)\n",
    "* [history/SNF-0203-ALLEG](http://snf.in2p3.fr/history/SNF-0203-ALLEG/) (Job name)\n",
    "\n",
    "### Cube thumbs\n",
    "\n",
    "* [thumbs/SNF20070820-000/SNF-0200](http://snf.in2p3.fr/thumbs/SNF20070820-000/SNF-0200/) (target/job)\n",
    "\n",
    "### Light-curve comparison\n",
    "\n",
    "* [comparelc/SNF-0200-BEDELLa/SNF-0117-ACESa](http://snf.in2p3.fr/comparelc/SNF-0200-BEDELLa/SNF-0117-ACESa/) (jobname1/jobname2)\n",
    "\n",
    "### Time series exploration\n",
    "\n",
    "* [timeseries/SNF20070820-000](http://snf.in2p3.fr/timeseries/SNF20070820-000/) (target)\n",
    "* [timeseries/SNF20070820-000/666/720](http://snf.in2p3.fr/timeseries/SNF20070820-000/666/720/) (target/Fclass/XFclass)\n",
    "* [timeseries/SNF20070820-000/0200/666/720](http://snf.in2p3.fr/timeseries/SNF20070820-000/0200/666/720/) (target/Version/FClass/XFclass)\n",
    "* [timeseries/SNF20070820-000/0200/666/720/07235/07253](http://snf.in2p3.fr/timeseries/SNF20070820-000/0200/666/720/07235/07253/) (target/Version/FClass/XFclass/from/to)\n",
    "* [timeseries/SNF20070820-000/SNF-0200-BEDELL/666/720/07235/07253](http://snf.in2p3.fr/timeseries/SNF20070820-000/SNF-0200-BEDELL/666/720/07235/07253/) (target/Job/FClass/XFclass/from/to)\n",
    "\n",
    "### MFR information\n",
    "\n",
    "* [mfr/10189069006](http://snf.in2p3.fr/mfr/10189069006/) (IdPose)\n",
    "* [mfr/10189069006/-118](http://snf.in2p3.fr/mfr/10189069006/-118) (IdPose/Version)\n",
    "     \n",
    "### Final ref. and phot. nights attrition\n",
    "\n",
    "* [attrition/ref](http://snf.in2p3.fr/attrition/ref/)\n",
    "* [attrition/phot](http://snf.in2p3.fr/attrition/phot/)\n",
    "* [attrition/target](http://snf.in2p3.fr/attrition/target/)\n",
    "    \n",
    "### SNfactory target samples  \n",
    "\n",
    "* [samples](http://snf.in2p3.fr/samples)\n",
    "     \n",
    "### Data extractors\n",
    "\n",
    "* [redshift/SNF20070820-00](http://snf.in2p3.fr/redshift/SNF20070820-000/) (target)\n",
    "* [joberrors/SNF-0202-ES](http://snf.in2p3.fr/joberrors/SNF-0202-ES/) (jobname)\n",
    "\n",
    "### Photometricity\n",
    "\n",
    "* http://snovae.in2p3.fr/snprod/PhotoNight/2009/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SNID data\n",
    "\n",
    "`snid` (see the [online](http://people.lam.fr/blondin.stephane/software/snid/) documentation) is used as a \"Supernova Identification\" tools. Its latest version along with several spectral templates are install at CC-IN2P3 and available under the `snprod` account (or other snovae accounts). It has been run on all the SNfactory data. Below is presented the output of this run as well as the tools used to do it.  \n",
    "\n",
    "### Where and how to get them\n",
    "\n",
    "#### In the IDR\n",
    "\n",
    "Will come soon\n",
    "\n",
    "#### In the raw pickle file\n",
    "\n",
    "The main pickle file containing all the `snid` info on our spectra is located under\n",
    "\n",
    "        /afs/in2p3.fr/group/snovae/snprod1/SNID/snid_db_data.pkl\n",
    "        \n",
    "This file contains a dictionnary having for mains keys a list of supernova. For each supernova, a dictionnary containing info on the target and its spectra is available. It has the following structure (with 'd[sn]' being the main dictionnary for a given sn):\n",
    "\n",
    "* d[sn]['Target']: dictonnary of the DB Target info for the given supernova (Kind, Type, Name, etc.)\n",
    "* d[sn]['spectra']: dictionnary of spectra, having the following structure for, as an example, \n",
    "\n",
    "        d['SNF20080512-003']['spectra']['08_134_082_003_2_038_100_02-02_000']\n",
    "        \n",
    "        {'SALT2': -999, # -999 if no info in the given production\n",
    "         'SNID': {'salt2.phase': -999, # same as above\n",
    "                  'salt2.phase.info': 'No SALT2 information!. Probably not an IDR input spectrum.', # info \n",
    "                  'snid.best_match': 'sn1997dq', # the best match SN found by SNID\n",
    "                  'snid.best_rlap': 10.289999999999999, # the rlap value for the above best match\n",
    "                  'snid.best_stype': 'Ic-broad', # the sub-type of the above best match\n",
    "                  'snid.info': 'raw snid results using rlap > 5.0. See `snid` documentation.', # some info on the snid run\n",
    "                  'snid.phase': 18.0, # the phase of the spectrum as estimated by snid\n",
    "                  'snid.phase.err': 24.72, # the error on the estimated phase\n",
    "                  'snid.redshift': 0.0374, # the redshift (could be given as an input to snid or estimated, see info)\n",
    "                  'snid.rlapmin': 5.0, # the minum rlap used to estimate the tpe and subtype\n",
    "                  'snid.subtype': 'Ic-broad', # the estimate subtype\n",
    "                  'snid.type': 'Ic' # the estimate type\n",
    "                 }\n",
    "        }\n",
    "        \n",
    "This pickle file has been created using `runSNID.py` with the --DB and -G options, on the (Fclass, XFclass, Version) = (38, 100, 202) spectra.\n",
    "\n",
    "As an example, here is a few python command lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target is SNF20080512-003\n",
      "Target info\n",
      "{'Kind': u'SuperNova', 'Dec': 36.5222138889, 'MWebv': 0.0206, 'Name': u'SNF20080512-003', 'Redshift': 0.032, 'IdTarget': u'T08134081', 'Type': u'Ic', 'DateC': datetime.datetime(2008, 7, 2, 17, 31, 52, 132915), 'Ra': 254.734958333, 'IAUC': None, 'PI': u'SNfactory', 'DateM': datetime.datetime(2009, 6, 3, 15, 35, 13, 974751), 'id': 2198}\n",
      "Info on a give nspectrum\n",
      "{'SNID': {'snid.phase': 18.0, 'salt2.phase.info': 'No SALT2 information!. Probably not an IDR input spectrum.', 'snid.type': 'Ic', 'snid.best_stype': 'Ic-broad', 'snid.subtype': 'Ic-broad', 'snid.best_rlap': 10.289999999999999, 'snid.rlapmin': 5.0, 'snid.phase.err': 24.72, 'salt2.phase': -999, 'snid.redshift': 0.0374, 'snid.best_match': 'sn1997dq', 'snid.info': 'raw snid results using rlap > 5.0. See snid documentation.'}, 'SALT2': -999}\n"
     ]
    }
   ],
   "source": [
    "import cPickle\n",
    "d = cPickle.load(open('/afs/in2p3.fr/group/snovae/snprod1/SNID/snid_db_data.pkl'))\n",
    "print \"Target is SNF20080512-003\"\n",
    "print \"Target info\\n\", d['SNF20080512-003']['Target']\n",
    "print \"Info on a give nspectrum\\n\", d['SNF20080512-003']['spectra']['08_134_082_003_2_038_100_02-02_000']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to build/update them\n",
    "\n",
    "To run `snid` on the SNfactory data, you can use `runSNID.py` at CC-IN2P3. It comes with different options, and can run on different inputs (IDr, zoo tarball, single spectrum, all of them taken in the DB) and differents type of files (Fclass / XFclass / Version). Here are the available options:\n",
    "\n",
    "      --version             show program's version number and exit\n",
    "      -h, --help            show this help message and exit\n",
    "      -i IDR, --idr=IDR     IDR path.\n",
    "      -z ZOO, --zoo=ZOO     Zoo tarball.\n",
    "      -t TARGET, --target=TARGET\n",
    "                            Target name.\n",
    "      -s SPECTRUM, --spectrum=SPECTRUM\n",
    "                            Spectrum or a list of spectra (Comma separated). Get\n",
    "                            it from the DB if not in the current directory\n",
    "      --DB                  Run SNID on all DB spectra for new SNe not in \n",
    "                            /afs/in2p3.fr/group/snovae/snprod1/SNID/snid_db_data.pkl\n",
    "      -G, --global_update   Run SNID on all DB spectra and update them in \n",
    "                            /afs/in2p3.fr/group/snovae/snprod1/SNID/snid_db_data.pkl\n",
    "      -f FCLASS, --fclass=FCLASS\n",
    "                            Fclass of the spectra in DB mode [38].\n",
    "      -x XFCLASS, --xfclass=XFCLASS\n",
    "                            XFclass of the spectra in DB mode [100].\n",
    "      -v DBVER, --dbver=DBVER\n",
    "                            Code version of the spectra in DB mode [203].\n",
    "      -T, --template        Print info on the available SNID spectral templates\n",
    "                            and quit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get information about the SNID templates available with the SNID wrapper from the ToolBox:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from ToolBox.Wrappers import SNID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 SNID template(s) found:\n",
      " \n",
      "Template /Users/nchotard/local/snid-5.0/templates\n",
      "\n",
      "INFO:\n",
      "111 templates (111 targets) loaded from /Users/nchotard/local/snid-5.0/templates/\n",
      "This template set contains the following types/substypes:\n",
      "\n",
      "Types:\n",
      " - II: 14 objects, 357 spectra\n",
      " - Ia: 48 objects, 718 spectra\n",
      " - Ib: 16 objects, 191 spectra\n",
      " - Ic: 17 objects, 211 spectra\n",
      " - NotSN: 16 objects, 38 spectra\n",
      "\n",
      "Sub-types:\n",
      " - AGN: 1 objects, 1 spectra\n",
      " - Gal: 11 objects, 11 spectra\n",
      " - II-pec: 1 objects, 93 spectra\n",
      " - IIL: 3 objects, 27 spectra\n",
      " - IIP: 7 objects, 163 spectra\n",
      " - IIb: 4 objects, 113 spectra\n",
      " - IIn: 3 objects, 74 spectra\n",
      " - Ia-91T: 5 objects, 63 spectra\n",
      " - Ia-91bg: 4 objects, 71 spectra\n",
      " - Ia-csm: 2 objects, 27 spectra\n",
      " - Ia-norm: 32 objects, 473 spectra\n",
      " - Ia-pec: 5 objects, 84 spectra\n",
      " - Ib-norm: 11 objects, 48 spectra\n",
      " - Ib-pec: 1 objects, 30 spectra\n",
      " - Ic-broad: 4 objects, 88 spectra\n",
      " - Ic-norm: 13 objects, 123 spectra\n",
      " - LBV: 3 objects, 15 spectra\n",
      " - M-star: 1 objects, 11 spectra\n",
      "\n",
      " - Total: 111 objects, 1515 spectra\n",
      "\n",
      " \n",
      "Template /Users/nchotard/local/snid-5.0/templates-2.0\n",
      "\n",
      "INFO:\n",
      "349 templates (349 targets) loaded from /Users/nchotard/local/snid-5.0/templates-2.0/\n",
      "This template set contains the following types/substypes:\n",
      "\n",
      "Types:\n",
      " - II: 14 objects, 533 spectra\n",
      " - Ia: 283 objects, 2724 spectra\n",
      " - Ib: 19 objects, 239 spectra\n",
      " - Ic: 17 objects, 226 spectra\n",
      " - NotSN: 16 objects, 38 spectra\n",
      "\n",
      "Sub-types:\n",
      " - AGN: 1 objects, 1 spectra\n",
      " - Gal: 11 objects, 11 spectra\n",
      " - II-pec: 1 objects, 241 spectra\n",
      " - IIL: 3 objects, 27 spectra\n",
      " - IIP: 7 objects, 190 spectra\n",
      " - IIb: 5 objects, 128 spectra\n",
      " - IIn: 3 objects, 75 spectra\n",
      " - Ia-91T: 25 objects, 340 spectra\n",
      " - Ia-91bg: 25 objects, 193 spectra\n",
      " - Ia-csm: 2 objects, 27 spectra\n",
      " - Ia-norm: 222 objects, 1995 spectra\n",
      " - Ia-pec: 9 objects, 169 spectra\n",
      " - Ib-norm: 12 objects, 60 spectra\n",
      " - Ib-pec: 2 objects, 51 spectra\n",
      " - Ic-broad: 5 objects, 103 spectra\n",
      " - Ic-norm: 12 objects, 123 spectra\n",
      " - LBV: 3 objects, 15 spectra\n",
      " - M-star: 1 objects, 11 spectra\n",
      "\n",
      " - Total: 349 objects, 3760 spectra\n",
      "\n",
      " \n",
      "Template /Users/nchotard/local/snid-5.0/templates_bsnip_v7.0\n",
      "\n",
      "INFO:\n",
      "328 templates (306 targets) loaded from /Users/nchotard/local/snid-5.0/templates_bsnip_v7.0/\n",
      "This template set contains the following types/substypes:\n",
      "\n",
      "Types:\n",
      " - II: 113 objects, 482 spectra\n",
      " - Ia: 134 objects, 738 spectra\n",
      " - Ib: 16 objects, 132 spectra\n",
      " - Ic: 14 objects, 150 spectra\n",
      " - NotSN: 29 objects, 51 spectra\n",
      "\n",
      "Sub-types:\n",
      " - AGN: 1 objects, 1 spectra\n",
      " - C-star: 3 objects, 3 spectra\n",
      " - Gal: 11 objects, 11 spectra\n",
      " - II-pec: 3 objects, 14 spectra\n",
      " - IIP: 76 objects, 330 spectra\n",
      " - IIb: 10 objects, 117 spectra\n",
      " - IIn: 34 objects, 138 spectra\n",
      " - Ia-02cx: 4 objects, 46 spectra\n",
      " - Ia-91T: 3 objects, 44 spectra\n",
      " - Ia-91bg: 16 objects, 70 spectra\n",
      " - Ia-99aa: 7 objects, 44 spectra\n",
      " - Ia-csm: 2 objects, 30 spectra\n",
      " - Ia-norm: 101 objects, 478 spectra\n",
      " - Ia-pec: 1 objects, 26 spectra\n",
      " - Ib-norm: 6 objects, 15 spectra\n",
      " - Ic-broad: 3 objects, 90 spectra\n",
      " - Ic-norm: 10 objects, 33 spectra\n",
      " - Ic-pec: 1 objects, 27 spectra\n",
      " - LBV: 3 objects, 15 spectra\n",
      " - M-star: 7 objects, 17 spectra\n",
      " - QSO: 4 objects, 4 spectra\n",
      "\n",
      " - Total: 306 objects, 1553 spectra\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SNID.list_templates(info=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Host data\n",
    "\n",
    "### Local host\n",
    "\n",
    "For now, you can get the local host data [here](http://snovae.in2p3.fr/rigault/LocalHost/data/current/SNe_frefs_and_psfsubs_1.0.pkl) and the web analysis web page at [this location](http://snovae.in2p3.fr/rigault/LocalHost/data/current/).\n",
    "\n",
    "### Global host\n",
    "\n",
    "The global host galaxy information computed by Mike Childress are stored into a pkl file, available [here](http://snovae.in2p3.fr/snprod/Data/IDR/Additional_Data/MC_Host_SnfMetaData_compatible.pkl). The data are only available up to mid 2010. \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
