{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Things to know\n",
    "\n",
    "## When do we run the data production?\n",
    "\n",
    "The data processing happens under two circumstances:\n",
    "\n",
    "* When a full re-processing of the data is needed. In that case, all the following plans have to be run in order on all nights/targets available at the moment. It is usually done when a new code version is available, due to important changes is several pieces of the codes (SNF-0202 -> SNF-0203). When it happens, the first step is to produce these lists of nights/targets using the two scripts listed below. All the plan will then be run using `wrap_batch_jobs`, as explain below and in the [cookbook](SNfactoryDataProcessing.html) section.\n",
    "    * `list_night` to create the list of nights on which the plans will be run;\n",
    "    * `list_followed_targets`, to create the list of targets on which the plans will be run.\n",
    "* When there are new observations, usually for a few nights. The plans will thus be run in their **incremental** mode. This is only true for the ones running on the night level. We usually run the incremental production from `plan_file_quality` to `plan_gs_psf`.\n",
    "* When a new \"flux production\" is needed to be run. This is actually what happens most of the time. Since the first few steps of the pipeline (up to `plan_extract_star`) are now quite stable, the re-processing of the data is usually done based on the incremental production of the few first steps. It is thus usually done as followed:\n",
    "    * data transfer -> `plan_gs_psf`: incremental mode of the production (nights oriented plans). Usually done on a few new nights during which SNIFS has been used. This includes the following steps:\n",
    "        * Data transfer and summit cleaning;\n",
    "        * DB header update, data filling, and DB update (`snf_header`, `snf_db_make`, `snf_db_fill`, `SyncTarget`, `FlagRunKind`);\n",
    "        * `plan_file_quality`;\n",
    "        * `plan_cube_generation`;\n",
    "        * `plan_extract_star`;\n",
    "        * `plan_multi_standard`;\n",
    "        * `tabPhotometricity`\n",
    "        * `plan_photometric_ratios`;\n",
    "        * `plan_gs_psf`;\n",
    "\n",
    "    * `plan_flux_solution` -> `plan_analyse_timeseries`: full reprocessing (target oriented plans). Usually done on the full sample (~1300 targets). This includes the following steps:\n",
    "        * `plan_flux_solution`;\n",
    "        * `plan_flux_calibration`;\n",
    "        * `plan_cubefit`;\n",
    "        * `plan_extract_star`\n",
    "        * `plan_analyze_timeseries`.\n",
    "        \n",
    "**Note**: some of the plans can be both night and target oriented, e.g., `plan_extract_star`.\n",
    "\n",
    "\n",
    "## Post-mortem jobs\n",
    "\n",
    "The `Osiris` job runs continously in the demon queue, and takes care of post-mortem analysis of our jobs: it fetches the exit status, stdout and stderr output logs of the finished jobs, stores them and changes the job status in the DB. This only concerns jobs that are launched via `batch_jobs` and `snf_qsub`, and Osiris runs every 10min updating any jobs that were finished in the meantime. Demon jobs can run indefinitely but are limited to 24h CPU time, so to be on the safe side Osiris will stop automatically after 7 days, when a backup job (`Anubis`) takes over, changes its name to Osiris, spawns a new child job, and so on...\n",
    "\n",
    "### Launching Osiris by hand\n",
    "\n",
    "In case `Osiris` does not seem to be properly working (the Job.Status are not being flagged as **ENDED**) or if neither `Osiris` nor `Anubis` are in the queue, we need to relaunch them:\n",
    "\n",
    "        qdel Osiris Anubis` (if they are running and seem bugged)\n",
    "        qsub $SNF_TASKS/Processing/scripts/osiris.sh\n",
    "\n",
    "The logs (if any) of the post-mortem jobs are stored in `\\$HOME/db/SGE/osiris`.\n",
    "\n",
    "`Osiris` will only update jobs which are launched *after* it starts. In other words, if you've been launching hundreds of jobs for two days and =Osiris= was stuck, this procedure will not fix the jobs. For that you either need to update by hand each job (see next section) or you can force the timestamp taken as reference for `Osiris`, like this:\n",
    "\n",
    "        date\n",
    "        Wed Sep 26 09:40:48 CEST 2012\n",
    "        date --date \"24 september 2012\"\n",
    "        Mon Sep 24 00:00:00 CEST 2012\n",
    "        date --date \"24 september 2012\" +%s\n",
    "        1348437600\n",
    "        qsub $SNF_TASKS/Processing/scripts/osiris.sh 1348437600\n",
    "\n",
    "This will force `Osiris` to search for jobs to update which were stored in the last 2 days (we're the 26th, the timestamp we gave it is for the 24th).\n",
    "\n",
    "### Update job status by hand\n",
    "\n",
    "The `Osiris` job updates the status of the finished jobs every 10 minutes. Sometimes it may miss a job, which will have a Job.Status in the DB as **Ending**. You can update the status of the job by hand, if you have the original .out and .err files for the job:\n",
    "\n",
    "        cd $JOBDIR/&lt;job output dir&gt;/\n",
    "        update_sge_job &lt;filename&gt;.out &lt;filename&gt;.err\n",
    "\n",
    "## Launching jobs\n",
    "\n",
    "We use two different script to launch jobs: `batch_jobs` and `wrap_batch_jobs`\n",
    "\n",
    "\n",
    "### `batch_jobs`\n",
    "`batch_jobs` is a wrapper to create a bunch of job scripts via one of these plan script (in order of their use in the cookbook):\n",
    "\n",
    "* `plan_file_quality`        (z)\n",
    "* `plan_cube_generation`     (c)\n",
    "* `plan_extract_star`        (e)\n",
    "* `plan_multi_standard`      (m)\n",
    "* `plan_photometric_ratios`  (h)\n",
    "* `plan_gs_psf`              (g)\n",
    "* `plan_flux_solution`       (x)\n",
    "* `plan_transmission`        (t)\n",
    "* `plan_flux_calibration`    (f)\n",
    "* `plan_ddt`                 (d)\n",
    "* `plan_cubefit`             (b)\n",
    "* `plan_analyze_timeseries`  (a)\n",
    "   \n",
    "The most import options of `batch_jobs` are:\n",
    "\n",
    "* --prefix: set job prefix (required);\n",
    "* --meta_prefix: change the SNF- preprefix (e.g. to your initials for debug runs);\n",
    "* --mode: set mode, e.g. plan_file_preprocessing or p (required when creating, optional with --submit);\n",
    "* --outver: Force the output version; if present this argument will be added to the -a option;\n",
    "* --args: pass ARGS to plan_* command (use quotes!);\n",
    "* --nodb: use option '--no_register' in plan scripts;\n",
    "* --keep: keep going even if a plan_* or submit fails;\n",
    "* --submit: submit the already created job scripts using snf_qsub (or qsub if --nodb was used to create);\n",
    "* --autosubmit: automatically submit the jobs if script creation succeeds.\n",
    "\n",
    "### `wrap_batch_jobs`\n",
    "\n",
    "`wrap_batch_jobs` is a wrapper to `batch_jobs`, used to launch a production on a large list (more than 5-10) of target or nights. This wrapper takes a list and a `batch_jobs` command line, splits this list into several sub-lists, and launches the shell script production on the batch queue system. Launching a production takes only a few minutes with `wrap_batch_jobs` while it could take from 1 to ~10 hours using `batch_jobs` only."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run a production\n",
    "The SNfactory data production is made through the use of the scripts and plans introduced above. There are many steps in the production flow, each of them being dependant from (at least) the previous one. The productions are run at the CC IN2P3 under the *snprod* account. After connecting to the CC, there are a few steps and things to know before runing any kind of production code. For a more detailed presentation of each step of the production plan, have a look at the following [SNf twiki page](https://snf-doc.lbl.gov/twiki/bin/view/Tasks/NewDataProcessing).\n",
    "\n",
    "### Code versions\n",
    "The SNfactory code has changed a lot since the begining of the project, and some of its parts are still evolving. Each time we have though that the code was stable enough to run on a large scalde production, we have tagged it into a stable CVS version. By default, when connection to the CC under snprod, the last stable version is used, as seen in the prompt: *snprod@ccage009 [<font color='red'>SNF-02-02</font>] ~ $ *. The list of available code version can be obtained using the *snf_version* script:\n",
    "\n",
    "    snprod@ccage009 [SNF-02-02] ~ $ `snf_version`\n",
    "    Choose version among available ones:\n",
    "    HEAD\n",
    "    SNF-01-00\n",
    "    SNF-01-01\n",
    "    ...\n",
    "    SNF-02-00\n",
    "    SNF-02-01\n",
    "    SNF-02-02\n",
    "    \n",
    "To go from the current version to an other version, run the *snf_version* script again with the new version as argument:\n",
    "\n",
    "    snprod@ccage009 [SNF-02-01] ~ $ `snf_version` SNF-02-02\n",
    "    snprod@ccage009 [SNF-02-02] ~ $\n",
    "\n",
    "What actually changed during this operation are most of the environment variables, pointing to the code or other diretories used. For example:\n",
    "\n",
    "    snprod@ccage009 [SNF-02-01] ~ $ echo $JOBDIR\n",
    "    /afs/in2p3.fr/group/snovae/snprod/jobs/SNF-02-01\n",
    "    snprod@ccage009 [SNF-02-02] ~ $ echo $JOBDIR\n",
    "    /afs/in2p3.fr/group/snovae/snprod/jobs/SNF-02-02\n",
    "    \n",
    "    snprod@ccage009 [SNF-02-01] ~ $ echo $SNF_TASKS\n",
    "    /afs/in2p3.fr/group/snovae/snf/SNFactory/Tasks/SNF-02-01\n",
    "    snprod@ccage009 [SNF-02-02] ~ $ echo $SNF_TASKS\n",
    "    /afs/in2p3.fr/group/snovae/snf/SNFactory/Tasks/SNF-02-02\n",
    "\n",
    "\n",
    "\n",
    "### Job directory\n",
    "Jobs are usually launched **from** the following directory when working under *snprod*:\n",
    "\n",
    "    snprod@ccage019 [SNF-02-02] ~ $ cd $JOBDIR\n",
    "    snprod@ccage019 [SNF-02-02] jobs/SNF-02-02 $ pwd\n",
    "    /afs/in2p3.fr/group/snovae/snprodJob/SNF-02-02\n",
    "    \n",
    "Jobs will then be launch from the directory corresponding to the plan you want to launch (e.g. PES for *plan_extract_star*). Each plan is either night-oriented or target-oriented. In both cases, corresponding directories are automatically created by the *batch_jobs* script: \n",
    "\n",
    "    snprod@ccage019 [SNF-02-02] jobs/SNF-02-02 $ ls PES\n",
    "    04  05  06  07  08  09  10  11  12  13  14  CMD  nights.list  test.list\n",
    "\n",
    "\n",
    "### Launch a job\n",
    "To launch jobs, we usually use the following script to, first, create the list of night and targets:\n",
    "\n",
    "    `list_followed_targets`\n",
    "    `list_night`\n",
    "    \n",
    "and then launch the different plans using:\n",
    "\n",
    "    `batch_jobs` or `wrap_batch_jobs`\n",
    "    \n",
    "if you respectively have a few jobs to launch or a long list of jobs to launch. *batch_jobs* will interactively launch jobs for a given list of nights/targets, while wrap_batch_jobs will do it on different workers in parallel, making the jobs creation/launching much faster. Have a look at the different options and the many *CMD* files present in the job directories to find out what options have to be used for a given job. Here is an example using the last PES production made under SNF-02-02:\n",
    "\n",
    "    snprod@ccage019 [SNF-02-02] SNF-02-02/PES $ more CMD\n",
    "    `batch_jobs` -p ES${SNF_VERSION_LITE} -m e -a \"--truncateR 5100,9700 -R\" test.list \n",
    "\n",
    "When a job or list of job have been launch, you can check if it is in queue or running using the *qstat2* command:\n",
    "\n",
    "    snprod@ccage019 [SNF-02-02] SNF-02-02/PES $ qstat2\n",
    "    Jobname                  State  Time                            CPU\n",
    "    Osiris                       r  2014-11-24T09:16:17           503/0\n",
    "    SNF-0202-NEWMFRh-EG131       r  2014-11-26T14:25:59    60272/100000\n",
    "    SNF-0202-NEWMFRh-P177D       r  2014-11-27T16:39:25     1993/100000\n",
    "    Anubis                     hqw  2014-11-24T09:16:30             0/0\n",
    "    ---\n",
    "      3 running\n",
    "      1 queued\n",
    "      \n",
    "As it has been said above in the section on the SNfactory database, we currently can run up to 360 jobs at the time, other launched jobs are stored in the queue waiting for a slot to be freed. The DB can support up to 400 simultaneous connections, which should be enough to handle any production and personnal connections at the same time. All these limitations have been increased between July and December 2015, and were respectively for the number of jobs and possible connections to the DB of 120 and 250 before July 2015.\n",
    "      \n",
    "Here is a list of CC-IN2P3 documentation links about job submission:\n",
    "\n",
    "* Job submission: http://cc.in2p3.fr/docenligne/969#jobcheckstatus\n",
    "* Queues and limits: http://cctools.in2p3.fr/mrtguser/info_sge_queue.php\n",
    "* Snovae info on the CC: http://cctools.in2p3.fr/mrtguser/info_manips_detail.php?group=snovae\n",
    "* General info: http://cctools.in2p3.fr/mrtguser/\n",
    "\n",
    "### Managing jobs\n",
    "Managing a job or a list of job goes from launching them to cheking their results and outputs. Several tools have been written for this puporse:\n",
    "    \n",
    "* `qstat2`: check if a job has been correctly launched, if it is running, finished, or still in queue (see above).\n",
    "* `jobErrors`: check the .err and .out of a job for errors. Works only on regular jobs, i.e not on MFR (python scripts), DDT (no .err) or cubefit (not *SNf* standard* outputs) jobs.\n",
    "* `check_job_output`: compare the number of files that should have beem registered at the end of a job and what have actually been registered in the DB after the job ends.\n",
    "* `job_attrition`: for a given directory, check for *missing* jobs, i.e, not launched, launch but not registered, launched but killed, etc.\n",
    "* `manage_jobs`: check if a job or list of jobs exist in the DB, to check or change their status, the number of associated processes, and to deleted a job in case of problem. When deleting a job, be very careful and first make sure that you won't delete jobs that we want to keep. When doing so, you will erase all files from disk and from the DB, and will not be able to come back to the previous state. Use option -db instead of -d. It will create a file that you will have to launch manually. Check its content before submiting it to the queue. Option -n will show you the list of jobs with no associated processes, which should be empty.\n",
    "* `srb_cleanup`: compare data on disk and in the DB. Look for missing data either in the DB or on disk.\n",
    "* `job_env_check`: check the environement variables of a job, or campare it for two jobs.\n",
    "\n",
    "### Personal Production\n",
    "\n",
    "There is a few options in `batch_jobs` allowing to submit \"personal/test\" production which will not interfere with the main production.\n",
    "\n",
    "#### No registration in the DB\n",
    "\n",
    "To not record the result of your prod in the central archive disks and in the DB, you just need to add the \"-L\" option when running the `batch_jobs` script. In this case, not only the produced files will not be registered in the DB, but the job will run in the directory from which `batch_jobs` -s had submitted the jobs, allowing to recover the produced file in this same directory.\n",
    "\n",
    "#### Registration in the DB\n",
    "\n",
    "Each SNFactory member (should) has a \"production ID\" (Central test=0 , Steven=1 , Pierre=2, ... ask yours if you don't know it). This \"production ID\" can be used at production time to identify your test production and to not interfere with the main production. This \"production ID\" is passed to the generation/submition of the jobs throught the --outver=\"Production ID\" option of `batch_jobs`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual DB-update recipe\n",
    "\n",
    "The DB is \"automatically\" updated when new data comes while the first steps of the pipeline are run (see steps [A](SNfactoryDataProcessing.html#a-header-db-update), [B](SNfactoryDataProcessing.html#b-db-update) and [C](SNfactoryDataProcessing.html#c-update-target-run-info) of the data processing cookbook). Unfortunately, it sometimes appears that the Target.Kind (and Type) and Run.Kind of specific targets is not updated correctly, or at least not the way we would like it to be. Some of these (good) targets will thus have their Kind set to 'Unknown', or some other undesirable values (same for the Run.Kind). It is then necessary for these targets and their runs to be manually modified in the DB so they can be processed by the pipeline like other regular targets. To do so, we use the following command lines, which will have to be adapted to the specific targets/runs that you would like to modify in the DB.\n",
    "\n",
    "### Change a Target.Kind\n",
    "\n",
    "First, let's import the DB tables we will work on (usually the Target and Run tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from processing.process.models import Target, Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then have to get the target (could be a run, see below) we would like to modify in the DB. \n",
    "\n",
    "**Note**: the selected target (G27-45) hasn't been observed by SNfactory but by an other PI (Willman), so it is quite safe to interactively change some of its values, as loong as we change them back at the end of the example session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G27-45 unkonwn NotSnf Willman\n"
     ]
    }
   ],
   "source": [
    "tg = Target.objects.get(Name='G27-45')\n",
    "print tg.Name, tg.Kind, tg.Type, tg.PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To modify the Kind or Type (or any other values) of this target in the DB, simply change them in your ipython first, and save them in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tg.Kind = 'NewKind'\n",
    "tg.Type = 'NewType'\n",
    "tg.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now check that the changes have been correctly saved in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G27-45 NewKind NewType\n"
     ]
    }
   ],
   "source": [
    "tg = Target.objects.get(Name='G27-45')\n",
    "print tg.Name, tg.Kind, tg.Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And changed them back to their original values (you won't change them back in the real life)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "G27-45 unkonwn NotSnf\n"
     ]
    }
   ],
   "source": [
    "tg.Kind = 'unkonwn'\n",
    "tg.Type = 'NotSnf'\n",
    "tg.save()\n",
    "tg = Target.objects.get(Name='G27-45')\n",
    "print tg.Name, tg.Kind, tg.Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You can use `Target.objects.filter(Name__in='SOMEPATTERN')` or `__regex`, `__contains`, `__startswith` to get several targets in case you want to apply the same type of modifications to a serie of targets. See the [DB data access](DataAccess.html#from-the-db) section for examples of more comple queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change a Run.Kind\n",
    "\n",
    "Any table can be changed using the same scheme. For example, you can apply the same method and change the Run.Kind for all runs of the above target by looping on the runs (but we will only change one of them in this example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8255097 unkonwn PHOTO\n",
      "8255098 unkonwn PHOTO\n",
      "8255064 unkonwn ACQUISITION\n",
      "8255065 unkonwn PHOTO\n",
      "8255066 unkonwn PHOTO\n",
      "8255067 unkonwn PHOTO\n",
      "8255068 unkonwn PHOTO\n",
      "8255069 unkonwn PHOTO\n",
      "8255092 unkonwn ACQUISITION\n",
      "8255093 unkonwn ACQUISITION\n",
      "8255094 unkonwn PHOTO\n",
      "8255095 unkonwn PHOTO\n",
      "8255096 unkonwn PHOTO\n"
     ]
    }
   ],
   "source": [
    "for r in tg.Runs_FK.all():\n",
    "    print r.IdRun, r.Kind, r.Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To change one of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8255098 G27-45 unkonwn\n"
     ]
    }
   ],
   "source": [
    "r = Run.objects.get(IdRun=8255098)\n",
    "print r.IdRun, r.TargetId_FK.Name, r.Kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NewRunKind\n"
     ]
    }
   ],
   "source": [
    "r.Kind = 'NewRunKind'\n",
    "print r.Kind\n",
    "r.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then make sure it has been saved in the DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8255097 unkonwn PHOTO\n",
      "8255098 NewRunKind PHOTO\n",
      "8255064 unkonwn ACQUISITION\n",
      "8255065 unkonwn PHOTO\n",
      "8255066 unkonwn PHOTO\n",
      "8255067 unkonwn PHOTO\n",
      "8255068 unkonwn PHOTO\n",
      "8255069 unkonwn PHOTO\n",
      "8255092 unkonwn ACQUISITION\n",
      "8255093 unkonwn ACQUISITION\n",
      "8255094 unkonwn PHOTO\n",
      "8255095 unkonwn PHOTO\n",
      "8255096 unkonwn PHOTO\n"
     ]
    }
   ],
   "source": [
    "for r in tg.Runs_FK.all():\n",
    "    print r.IdRun, r.Kind, r.Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And of course, change it back to its original value and save it, since we do not really want to change anything in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8255098 G27-45 NewRunKind\n"
     ]
    }
   ],
   "source": [
    "r = Run.objects.get(IdRun=8255098)\n",
    "print r.IdRun, r.TargetId_FK.Name, r.Kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "r.Kind = 'unkonwn'\n",
    "r.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And check again before leaving this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8255098 G27-45 unkonwn\n"
     ]
    }
   ],
   "source": [
    "r = Run.objects.get(IdRun=8255098)\n",
    "print r.IdRun, r.TargetId_FK.Name, r.Kind"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can of course do that while looping on the list of runs for a given target (`tg.Run_FK.all()`), but be carful to always check what you have changed locally before saving anything in the DB, i.e., before applying the `.save()`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
